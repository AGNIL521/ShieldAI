{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhanced Interactive Exploration: Adversarial Attacks & Defenses\n",
    "\n",
    "This notebook allows you to interactively run and visualize adversarial attacks and defenses on image and text classifiers. It also demonstrates anomaly detection for adversarial monitoring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Imports\n",
    "Ensure all dependencies are installed and simulation scripts are accessible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath('simulation'))\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from simulation import attack_demo, nlp_attack_demo, ids_attack_demo, defense_adversarial_training, defense_input_randomization, monitoring_example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Image Classifier Adversarial Attack Demo\n",
    "Run and visualize the effect of an adversarial example on a simple image classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fooled = attack_demo.run_attack_demo(plot=True)\n",
    "print(f'Adversarial attack successful? {fooled}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. NLP Adversarial Attack Demo\n",
    "See how simple text perturbations can fool a spam classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_acc, adv_acc, results = nlp_attack_demo.run_nlp_demo()\n",
    "print(f'Clean accuracy: {clean_acc:.2f}, Adversarial accuracy: {adv_acc:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. IDS Adversarial Attack Demo\n",
    "See how evasion can reduce detection accuracy in a synthetic IDS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_acc, adv_acc = ids_attack_demo.run_ids_demo()\n",
    "print(f'Clean accuracy: {clean_acc:.2f}, Adversarial accuracy: {adv_acc:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Defenses: Adversarial Training\n",
    "Test the effect of adversarial training on classifier robustness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_acc, adv_acc = defense_adversarial_training.run_adversarial_training_demo()\n",
    "print(f'Adversarially trained accuracy on clean: {clean_acc:.2f}, on adversarial: {adv_acc:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Defenses: Input Randomization\n",
    "Test the effect of input randomization as a defense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = defense_input_randomization.run_input_randomization_demo()\n",
    "print(f'Accuracy on adversarial+randomized inputs: {acc:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Monitoring: Adversarial Activity Detection\n",
    "Detect outliers/anomalies that may indicate adversarial activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags = monitoring_example.run_monitoring_demo()\n",
    "print(f'Potential adversarial samples at indices: {flags}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**You can modify and re-run cells to experiment with attack parameters, defense strategies, and detection thresholds!**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
